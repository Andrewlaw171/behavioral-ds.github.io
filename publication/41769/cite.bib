@article{41769,
 abstract = {Content sharing networks, such as YouTube, contain traces of both explicit online interactions (such as likes, comments, or subscriptions), as well as latent interactions (such as quoting, or remixing, parts of a video). We propose visual memes, or frequently re-posted short video segments, for detecting and monitoring such latent video interactions at scale. Visual memes are extracted by scalable detection algorithms that we develop, with high accuracy. We further augment visual memes with text, via a statistical model of latent topics. We model content interactions on YouTube with visual memes, defining several measures of influence and building predictive models for meme popularity. Experiments are carried out with over 2 million video shots from more than 40,000 videos on two prominent news events in 2009: the election in Iran and the swine flu epidemic. In these two events, a high percentage of videos contain remixed content, and it is apparent that traditional news media and citizen journalists have different roles in disseminating remixed content. We perform two quantitative evaluations for annotating visual memes and predicting their popularity. The proposed joint statistical model of visual memes and words outperforms an alternative concurrence model, with an average error of 2% for predicting meme volume and 17% for predicting meme lifespan.},
 author = {Lexing Xie and Apostol Natsev and Xuming He and John R. Kender and Matthew L. Hill and John R. Smith},
 doi = {10.1109/TMM.2013.2264929},
 journal = {IEEE Transactions on Multimedia},
 pages = {1244-1254},
 title = {Tracking Large-Scale Video Remix in Real-World Events},
 url_paper = {http://users.cecs.anu.edu.au/~xlx/papers/TMM-youtube.pdf},
 volume = {15, no. 6},
 year = {2013}
}

